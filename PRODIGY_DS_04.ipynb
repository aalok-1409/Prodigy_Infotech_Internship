{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPoljyObx3iPvrohcTuLhov",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aalok-1409/Prodigy_Infotech_Internship/blob/main/PRODIGY_DS_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3J_u2QaiEgf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "import re\n",
        "\n",
        "# Download NLTK stopwords if not already present\n",
        "nltk.download('stopwords', quiet=True)\n",
        "\n",
        "# Load data - UPDATE THIS FILENAME TO MATCH YOUR DOWNLOADED FILE\n",
        "try:\n",
        "    df = pd.read_csv('twitter_entity_sentiment.csv')  # Common filename for this dataset\n",
        "    print(\"Data loaded successfully!\")\n",
        "\n",
        "    # Display basic info\n",
        "    print(\"\\nData Overview:\")\n",
        "    print(df.head())\n",
        "    print(\"\\nColumns:\", df.columns.tolist())\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Original dataset not found. Creating sample data for demonstration...\")\n",
        "    # Create sample data if real dataset isn't available\n",
        "    sample_data = {\n",
        "        'tweet_text': [\n",
        "            'I love the new iPhone! Best phone ever #apple',\n",
        "            'Terrible customer service from @Amazon #disappointed',\n",
        "            'The weather is nice today',\n",
        "            'Windows 11 update broke my laptop #microsoft',\n",
        "            'Great job by the team @Tesla! #innovation'\n",
        "        ],\n",
        "        'sentiment': ['positive', 'negative', 'neutral', 'negative', 'positive'],\n",
        "        'entity': ['Apple', 'Amazon', 'Weather', 'Microsoft', 'Tesla']\n",
        "    }\n",
        "    df = pd.DataFrame(sample_data)\n",
        "    print(\"\\nSample data created for demonstration purposes\")\n",
        "\n",
        "## 1. Basic Sentiment Distribution\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x='sentiment', data=df,\n",
        "              palette={'positive':'green', 'neutral':'gray', 'negative':'red'},\n",
        "              order=['positive', 'neutral', 'negative'])\n",
        "plt.title('Overall Sentiment Distribution')\n",
        "plt.show()\n",
        "\n",
        "## 2. Sentiment by Entity\n",
        "if 'entity' in df.columns:\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    entity_order = df['entity'].value_counts().nlargest(10).index if len(df['entity'].unique()) > 10 else df['entity'].value_counts().index\n",
        "    sns.countplot(x='entity', hue='sentiment', data=df[df['entity'].isin(entity_order)],\n",
        "                  palette={'positive':'green', 'neutral':'gray', 'negative':'red'},\n",
        "                  hue_order=['positive', 'neutral', 'negative'])\n",
        "    plt.title('Sentiment Distribution by Entity')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.legend(title='Sentiment')\n",
        "    plt.show()\n",
        "\n",
        "## 3. Word Clouds by Sentiment\n",
        "def generate_wordcloud(text, title):\n",
        "    if len(text) > 0:\n",
        "        wordcloud = WordCloud(width=800, height=400,\n",
        "                             background_color='white',\n",
        "                             stopwords=set(stopwords.words('english'))).generate(text)\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.imshow(wordcloud)\n",
        "        plt.axis('off')\n",
        "        plt.title(title)\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\"No text available for {title}\")\n",
        "\n",
        "# Generate word clouds if tweet text exists\n",
        "if 'tweet_text' in df.columns:\n",
        "    # Positive words\n",
        "    positive_text = ' '.join(df[df['sentiment'] == 'positive']['tweet_text'].astype(str))\n",
        "    generate_wordcloud(positive_text, 'Frequent Words in Positive Tweets')\n",
        "\n",
        "    # Negative words\n",
        "    negative_text = ' '.join(df[df['sentiment'] == 'negative']['tweet_text'].astype(str))\n",
        "    generate_wordcloud(negative_text, 'Frequent Words in Negative Tweets')\n",
        "\n",
        "## 4. Hashtag Analysis\n",
        "if 'tweet_text' in df.columns:\n",
        "    def extract_hashtags(text):\n",
        "        return re.findall(r'#(\\w+)', str(text).lower())\n",
        "\n",
        "    df['hashtags'] = df['tweet_text'].apply(extract_hashtags)\n",
        "    all_hashtags = [tag for sublist in df['hashtags'] for tag in sublist]\n",
        "\n",
        "    if len(all_hashtags) > 0:\n",
        "        hashtag_counts = pd.Series(all_hashtags).value_counts().nlargest(20)\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        sns.barplot(x=hashtag_counts.values, y=hashtag_counts.index, palette='viridis')\n",
        "        plt.title('Top 20 Most Used Hashtags')\n",
        "        plt.xlabel('Count')\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"No hashtags found in the data\")\n",
        "\n",
        "print(\"\\nAnalysis complete!\")"
      ]
    }
  ]
}