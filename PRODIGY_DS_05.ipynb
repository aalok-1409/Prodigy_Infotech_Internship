{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNcNL4clJpSsUpKmF4hXS/a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aalok-1409/Prodigy_Infotech_Internship/blob/main/PRODIGY_DS_05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwScBD3yiNCD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import folium\n",
        "from folium.plugins import HeatMap\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style and figure parameters to prevent overlap\n",
        "plt.style.use('ggplot')\n",
        "sns.set_palette('viridis')\n",
        "plt.rcParams['figure.autolayout'] = True  # Automatically adjust subplots\n",
        "plt.rcParams['figure.constrained_layout.use'] = True  # Use constrained layout\n",
        "\n",
        "## 1. Data Loading and Preparation\n",
        "def load_data():\n",
        "    \"\"\"Load the dataset or create sample data if not available\"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv('US_Accidents_Dataset.csv')\n",
        "        print(\"Real dataset loaded successfully!\")\n",
        "        print(f\"Shape: {df.shape}\")\n",
        "        print(f\"Date range: {df['Start_Time'].min()} to {df['Start_Time'].max()}\")\n",
        "        return df\n",
        "    except FileNotFoundError:\n",
        "        print(\"Dataset not found. Creating sample data for demonstration...\")\n",
        "        np.random.seed(42)\n",
        "        dates = pd.date_range('2020-01-01', periods=5000, freq='H')\n",
        "        cities = ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix',\n",
        "                 'Philadelphia', 'San Antonio', 'San Diego', 'Dallas', 'San Jose']\n",
        "        states = ['CA', 'TX', 'NY', 'FL', 'PA', 'IL', 'OH', 'GA', 'NC', 'MI']\n",
        "\n",
        "        sample_data = {\n",
        "            'ID': range(5000),\n",
        "            'Severity': np.random.choice([1, 2, 3, 4], size=5000, p=[0.1, 0.6, 0.2, 0.1]),\n",
        "            'Start_Time': dates,\n",
        "            'End_Time': dates + pd.to_timedelta(np.random.randint(1, 120, size=5000), unit='m'),\n",
        "            'Weather_Condition': np.random.choice(['Clear', 'Rain', 'Snow', 'Fog', 'Cloudy', 'Thunderstorm'],\n",
        "                                               size=5000, p=[0.5, 0.2, 0.1, 0.05, 0.1, 0.05]),\n",
        "            'Sunrise_Sunset': np.random.choice(['Day', 'Night'], size=5000, p=[0.7, 0.3]),\n",
        "            'City': np.random.choice(cities, size=5000),\n",
        "            'State': np.random.choice(states, size=5000),\n",
        "            'Start_Lat': np.random.uniform(25, 49, size=5000),\n",
        "            'Start_Lng': np.random.uniform(-125, -67, size=5000),\n",
        "            'Temperature(F)': np.random.uniform(10, 100, size=5000),\n",
        "            'Visibility(mi)': np.random.uniform(0.1, 10, size=5000),\n",
        "            'Wind_Speed(mph)': np.random.uniform(0, 30, size=5000),\n",
        "            'Precipitation(in)': np.random.exponential(0.1, size=5000)\n",
        "        }\n",
        "        df = pd.DataFrame(sample_data)\n",
        "        print(\"Sample data created with realistic distributions\")\n",
        "        return df\n",
        "\n",
        "df = load_data()\n",
        "\n",
        "# Data cleaning and feature engineering\n",
        "def prepare_data(df):\n",
        "    \"\"\"Prepare the data for analysis\"\"\"\n",
        "    df['Start_Time'] = pd.to_datetime(df['Start_Time'])\n",
        "    df['Hour'] = df['Start_Time'].dt.hour\n",
        "    df['Weekday'] = df['Start_Time'].dt.day_name()\n",
        "    df['Month'] = df['Start_Time'].dt.month_name()\n",
        "    df['Year'] = df['Start_Time'].dt.year\n",
        "    df['Weather_Condition'] = df['Weather_Condition'].fillna('Unknown')\n",
        "    df['Sunrise_Sunset'] = df['Sunrise_Sunset'].fillna('Unknown')\n",
        "    df['Severity_Level'] = pd.cut(df['Severity'], bins=[0, 1, 2, 3, 4, 5],\n",
        "                                labels=['Minor', 'Moderate', 'Serious', 'Severe', 'Fatal'],\n",
        "                                right=False)\n",
        "    return df\n",
        "\n",
        "df = prepare_data(df)\n",
        "\n",
        "## 2. Temporal Analysis with Proper Spacing\n",
        "def plot_temporal_analysis(df):\n",
        "    \"\"\"Visualize temporal patterns with proper spacing\"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(18, 14))\n",
        "\n",
        "    # Hourly distribution\n",
        "    sns.countplot(ax=axes[0, 0], x='Hour', data=df)\n",
        "    axes[0, 0].set_title('Accidents by Hour of Day', fontsize=14)\n",
        "    axes[0, 0].set_xlabel('Hour of Day', fontsize=12)\n",
        "    axes[0, 0].set_ylabel('Number of Accidents', fontsize=12)\n",
        "\n",
        "    # Weekly distribution\n",
        "    weekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
        "    sns.countplot(ax=axes[0, 1], x='Weekday', data=df, order=weekday_order)\n",
        "    axes[0, 1].set_title('Accidents by Day of Week', fontsize=14)\n",
        "    axes[0, 1].set_xlabel('Day of Week', fontsize=12)\n",
        "    axes[0, 1].set_ylabel('Number of Accidents', fontsize=12)\n",
        "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    # Monthly distribution\n",
        "    month_order = ['January', 'February', 'March', 'April', 'May', 'June',\n",
        "                 'July', 'August', 'September', 'October', 'November', 'December']\n",
        "    sns.countplot(ax=axes[1, 0], x='Month', data=df, order=month_order)\n",
        "    axes[1, 0].set_title('Accidents by Month', fontsize=14)\n",
        "    axes[1, 0].set_xlabel('Month', fontsize=12)\n",
        "    axes[1, 0].set_ylabel('Number of Accidents', fontsize=12)\n",
        "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    # Severity by hour\n",
        "    sns.boxplot(ax=axes[1, 1], x='Severity', y='Hour', data=df)\n",
        "    axes[1, 1].set_title('Accident Severity by Hour of Day', fontsize=14)\n",
        "    axes[1, 1].set_xlabel('Severity Level', fontsize=12)\n",
        "    axes[1, 1].set_ylabel('Hour of Day', fontsize=12)\n",
        "\n",
        "    plt.tight_layout(pad=3.0)  # Add extra padding between subplots\n",
        "    plt.show()\n",
        "\n",
        "plot_temporal_analysis(df)\n",
        "\n",
        "## 3. Weather Analysis with Proper Spacing\n",
        "def plot_weather_analysis(df):\n",
        "    \"\"\"Analyze weather factors with proper spacing\"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(18, 14))\n",
        "\n",
        "    # Weather conditions\n",
        "    weather_counts = df['Weather_Condition'].value_counts().nlargest(10)\n",
        "    sns.barplot(ax=axes[0, 0], x=weather_counts.values, y=weather_counts.index)\n",
        "    axes[0, 0].set_title('Top 10 Weather Conditions', fontsize=14)\n",
        "    axes[0, 0].set_xlabel('Number of Accidents', fontsize=12)\n",
        "    axes[0, 0].set_ylabel('Weather Condition', fontsize=12)\n",
        "\n",
        "    # Severity by weather\n",
        "    weather_severity = df.groupby('Weather_Condition')['Severity'].mean().nlargest(10)\n",
        "    sns.barplot(ax=axes[0, 1], x=weather_severity.values, y=weather_severity.index)\n",
        "    axes[0, 1].set_title('Weather Conditions by Average Severity', fontsize=14)\n",
        "    axes[0, 1].set_xlabel('Average Severity', fontsize=12)\n",
        "    axes[0, 1].set_ylabel('Weather Condition', fontsize=12)\n",
        "\n",
        "    # Daylight conditions\n",
        "    sns.countplot(ax=axes[1, 0], x='Sunrise_Sunset', hue='Severity_Level', data=df)\n",
        "    axes[1, 0].set_title('Accidents by Daylight Condition', fontsize=14)\n",
        "    axes[1, 0].set_xlabel('Daylight Condition', fontsize=12)\n",
        "    axes[1, 0].set_ylabel('Number of Accidents', fontsize=12)\n",
        "    axes[1, 0].legend(title='Severity Level', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "    # Temperature distribution\n",
        "    if 'Temperature(F)' in df.columns:\n",
        "        sns.histplot(ax=axes[1, 1], x=df['Temperature(F)'], bins=30, kde=True)\n",
        "        axes[1, 1].set_title('Temperature Distribution', fontsize=14)\n",
        "        axes[1, 1].set_xlabel('Temperature (F)', fontsize=12)\n",
        "        axes[1, 1].set_ylabel('Number of Accidents', fontsize=12)\n",
        "\n",
        "    plt.tight_layout(pad=3.0)  # Add extra padding\n",
        "    plt.show()\n",
        "\n",
        "plot_weather_analysis(df)\n",
        "\n",
        "## 4. Geospatial Analysis (unchanged)\n",
        "def create_accident_map(df):\n",
        "    \"\"\"Create interactive map of accident hotspots\"\"\"\n",
        "    print(\"\\n Creating accident hotspot map...\")\n",
        "    sample_df = df.sample(n=2000, random_state=42) if len(df) > 2000 else df\n",
        "    avg_lat = sample_df['Start_Lat'].mean()\n",
        "    avg_lng = sample_df['Start_Lng'].mean()\n",
        "    m = folium.Map(location=[avg_lat, avg_lng], zoom_start=5, tiles='CartoDB dark_matter')\n",
        "    heat_data = [[row['Start_Lat'], row['Start_Lng']] for _, row in sample_df.iterrows()]\n",
        "    HeatMap(heat_data, radius=12, blur=15, max_zoom=13).add_to(m)\n",
        "\n",
        "    top_cities = df['City'].value_counts().nlargest(5).index\n",
        "    for city in top_cities:\n",
        "        city_df = df[df['City'] == city].sample(min(50, len(df[df['City'] == city])))\n",
        "        for _, row in city_df.iterrows():\n",
        "            popup_text = f\"\"\"\n",
        "            <b>City:</b> {row['City']}, {row['State']}<br>\n",
        "            <b>Severity:</b> {row['Severity']}<br>\n",
        "            <b>Weather:</b> {row['Weather_Condition']}<br>\n",
        "            <b>Time:</b> {row['Start_Time']}\n",
        "            \"\"\"\n",
        "            folium.CircleMarker(\n",
        "                location=[row['Start_Lat'], row['Start_Lng']],\n",
        "                radius=row['Severity'],\n",
        "                color='red' if row['Severity'] > 3 else 'orange',\n",
        "                fill=True,\n",
        "                fill_opacity=0.7,\n",
        "                popup=folium.Popup(popup_text, max_width=250)\n",
        "            ).add_to(m)\n",
        "\n",
        "    m.save('accident_hotspots.html')\n",
        "    print(\"Hotspot map saved as 'accident_hotspots.html'\")\n",
        "\n",
        "create_accident_map(df)\n",
        "\n",
        "## 5. Cross-Factor Analysis with Proper Spacing\n",
        "def plot_cross_factor_analysis(df):\n",
        "    \"\"\"Analyze relationships between factors with proper spacing\"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(18, 14))\n",
        "\n",
        "    # Weather vs time of day\n",
        "    weather_hour = df.groupby(['Hour', 'Weather_Condition']).size().unstack().fillna(0)\n",
        "    top_weather = df['Weather_Condition'].value_counts().nlargest(3).index\n",
        "    weather_hour[top_weather].plot(ax=axes[0, 0])\n",
        "    axes[0, 0].set_title('Accidents by Hour for Top 3 Weather Conditions', fontsize=14)\n",
        "    axes[0, 0].set_xlabel('Hour of Day', fontsize=12)\n",
        "    axes[0, 0].set_ylabel('Number of Accidents', fontsize=12)\n",
        "    axes[0, 0].legend(title='Weather Condition')\n",
        "\n",
        "    # Severity by weather and temperature\n",
        "    if 'Temperature(F)' in df.columns:\n",
        "        sns.scatterplot(ax=axes[0, 1], x='Temperature(F)', y='Severity',\n",
        "                       hue='Weather_Condition', data=df, alpha=0.6)\n",
        "        axes[0, 1].set_title('Severity by Temperature and Weather', fontsize=14)\n",
        "        axes[0, 1].set_xlabel('Temperature (F)', fontsize=12)\n",
        "        axes[0, 1].set_ylabel('Severity Level', fontsize=12)\n",
        "        axes[0, 1].legend(title='Weather Condition', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "    # City analysis\n",
        "    if 'City' in df.columns:\n",
        "        city_counts = df['City'].value_counts().nlargest(10)\n",
        "        sns.barplot(ax=axes[1, 0], x=city_counts.values, y=city_counts.index)\n",
        "        axes[1, 0].set_title('Top 10 Cities by Accident Count', fontsize=14)\n",
        "        axes[1, 0].set_xlabel('Number of Accidents', fontsize=12)\n",
        "        axes[1, 0].set_ylabel('City', fontsize=12)\n",
        "\n",
        "    # State analysis\n",
        "    if 'State' in df.columns:\n",
        "        state_severity = df.groupby('State')['Severity'].mean().sort_values(ascending=False)\n",
        "        sns.barplot(ax=axes[1, 1], x=state_severity.values, y=state_severity.index)\n",
        "        axes[1, 1].set_title('Average Severity by State', fontsize=14)\n",
        "        axes[1, 1].set_xlabel('Average Severity', fontsize=12)\n",
        "        axes[1, 1].set_ylabel('State', fontsize=12)\n",
        "\n",
        "    plt.tight_layout(pad=3.0)  # Add extra padding\n",
        "    plt.show()\n",
        "\n",
        "plot_cross_factor_analysis(df)\n",
        "\n",
        "## 6. Summary Statistics (unchanged)\n",
        "def show_summary_stats(df):\n",
        "    print(\"\\n SUMMARY STATISTICS\")\n",
        "    print(\"=\"*40)\n",
        "    print(\"\\n TEMPORAL DISTRIBUTION\")\n",
        "    print(\"-\"*30)\n",
        "    print(f\"Most common hour: {df['Hour'].mode()[0]}:00\")\n",
        "    print(f\"Most common weekday: {df['Weekday'].mode()[0]}\")\n",
        "    print(f\"Most common month: {df['Month'].mode()[0]}\")\n",
        "\n",
        "    print(\"\\n WEATHER CONDITIONS\")\n",
        "    print(\"-\"*30)\n",
        "    print(f\"Most common weather: {df['Weather_Condition'].mode()[0]}\")\n",
        "    print(f\"Weather with highest severity: {df.groupby('Weather_Condition')['Severity'].mean().idxmax()}\")\n",
        "\n",
        "    if 'City' in df.columns:\n",
        "        print(\"\\n LOCATION ANALYSIS\")\n",
        "        print(\"-\"*30)\n",
        "        print(f\"City with most accidents: {df['City'].value_counts().idxmax()}\")\n",
        "        print(f\"State with most accidents: {df['State'].value_counts().idxmax()}\")\n",
        "        print(f\"State with highest severity: {df.groupby('State')['Severity'].mean().idxmax()}\")\n",
        "\n",
        "    print(\"\\n SEVERITY ANALYSIS\")\n",
        "    print(\"-\"*30)\n",
        "    print(f\"Average severity: {df['Severity'].mean():.2f}\")\n",
        "    print(f\"Severity distribution:\\n{df['Severity_Level'].value_counts(normalize=True).mul(100).round(1)}\")\n",
        "\n",
        "show_summary_stats(df)"
      ]
    }
  ]
}